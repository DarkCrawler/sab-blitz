{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c845c-66e3-4ebd-a3f3-ed3530db55a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT_ID = 'qwiklabs-gcp-00-59947c43422f'\n",
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\"\n",
    "\n",
    "import kfp\n",
    "\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import component, pipeline, Artifact, ClassificationMetrics, Input, Output, Model, Metrics\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fbf168-99bd-45f3-af9e-15d351885cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION=\"us-central1\"\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f90b00-4a61-4b97-bcdd-ea8f1bb13488",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a7b5b-8e79-4d87-a077-b419f2c4c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the trainer file \n",
    "IMAGE_NAME = \"exodus_kfp\"\n",
    "TAG = \"latest\"\n",
    "TRAINING_CONTAINER_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}:{TAG}\"\n",
    "TRAINING_CONTAINER_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60217e-97e7-4686-8a58-73f0d16407d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --timeout 15m --tag $TRAINING_CONTAINER_IMAGE_URI trainer_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1903cab-1382-4f55-b22c-2d3cd0d7bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Custom code to create a component that creates pandas dataframe\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe68d2-3e39-49af-8e92-6144aebeb3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#def bq_pd_df_creater() -> NamedTuple(\"Outputs\",[(\"train_set\",pd.DataFrame),(\"eval_set\",pd.DataFrame)]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b317a277-482e-4941-99cf-d7ee0fed947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    output_component_file=\"bq_pandas_reader.yaml\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\",\"pandas\"],\n",
    ") \n",
    "def bq_pd_df_creater() -> NamedTuple(\"Outputs\",[(\"train_set\",pd.DataFrame),(\"eval_set\",pd.DataFrame)]):\n",
    "    from google.cloud import bigquery\n",
    "    bqclient = bigquery.Client()\n",
    "    \n",
    "    train_set_query = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM `qwiklabs-gcp-00-59947c43422f.kfp_test.full_data` AS train_set WHERE MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(train_set))), 10) IN (1, 2, 3, 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    eval_set_query = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM `qwiklabs-gcp-00-59947c43422f.kfp_test.full_data` AS train_set WHERE MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(train_set))), 10) IN (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    train_set=(\n",
    "        bqclient.query(train_set_query)\n",
    "        .result()\n",
    "        .to_dataframe(\n",
    "            # Optionally, explicitly request to use the BigQuery Storage API. As of\n",
    "            # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n",
    "            # API is used by default.\n",
    "            create_bqstorage_client=True,)\n",
    "    )\n",
    "    \n",
    "    eval_set=(\n",
    "        bqclient.query(eval_set_query)\n",
    "        .result()\n",
    "        .to_dataframe(\n",
    "            # Optionally, explicitly request to use the BigQuery Storage API. As of\n",
    "            # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n",
    "            # API is used by default.\n",
    "            create_bqstorage_client=True,)\n",
    "    )\n",
    "    \n",
    "    return (train_set,eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b99c73-04d9-4112-a1ea-6580788e9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "    output_component_file=\"bq_pandas_reader.yaml\",\n",
    "    packages_to_install=[\"google-cloud-aiplatform\",\"pandas\"],\n",
    ")\n",
    "def the_head_printer(\n",
    "    test_df,\n",
    "    eval_df\n",
    "):\n",
    "    return str(test_df[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f8380-a4e7-4e07-b73f-97b6caff8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name=\"hello-pandas\",\n",
    "    description=\"experiment with KF\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "# You can change the `text` and `emoji_str` parameters here to update the pipeline output\n",
    "def intro_pipeline(text: str = \"Vertex Pipelines\", emoji_str: str = \"sparkles\"):\n",
    "    train_eval_df_task = bq_pd_df_creater()\n",
    "    header_printer_task = the_head_printer(\n",
    "        test_df = train_eval_df_task.outputs[\"train_set\"],\n",
    "        eval_df = train_eval_df_task[\"eval_set\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b9b5a-970e-44b3-b49d-bd930cff833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=intro_pipeline, package_path=\"kf_bq_test.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1093ee5-6ea4-4f29-b24a-65648277e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bq_pd_df_creater():\n",
    "    from google.cloud import bigquery\n",
    "    bqclient = bigquery.Client()\n",
    "    \n",
    "    train_set_query = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM `qwiklabs-gcp-00-59947c43422f.kfp_test.full_data` AS train_set WHERE MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(train_set))), 10) IN (1, 2, 3, 4)\n",
    "    \"\"\"\n",
    "    \n",
    "    eval_set_query = \"\"\"\n",
    "    SELECT\n",
    "    *\n",
    "    FROM `qwiklabs-gcp-00-59947c43422f.kfp_test.full_data` AS train_set WHERE MOD(ABS(FARM_FINGERPRINT(TO_JSON_STRING(train_set))), 10) IN (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    train_set=(\n",
    "        bqclient.query(train_set_query)\n",
    "        .result()\n",
    "        .to_dataframe(\n",
    "            # Optionally, explicitly request to use the BigQuery Storage API. As of\n",
    "            # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n",
    "            # API is used by default.\n",
    "            create_bqstorage_client=True,)\n",
    "    )\n",
    "    \n",
    "    eval_set=(\n",
    "        bqclient.query(eval_set_query)\n",
    "        .result()\n",
    "        .to_dataframe(\n",
    "            # Optionally, explicitly request to use the BigQuery Storage API. As of\n",
    "            # google-cloud-bigquery version 1.26.0 and above, the BigQuery Storage\n",
    "            # API is used by default.\n",
    "            create_bqstorage_client=True,)\n",
    "    )\n",
    "    \n",
    "    return (train_set,eval_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f648ef-12b7-4f10-8a92-5c7ff448c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pandas_df = kfp.components.create_component_from_func(\n",
    "    func=bq_pd_df_creater,\n",
    "    output_component_file='bq_pandas_reader.yaml', # This is optional. It saves the component spec for future use.\n",
    "    base_image='gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest',\n",
    "    packages_to_install=['pandas','google-cloud-aiplatform'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda81351-2566-4a22-9c6b-1d34ea85082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    name=\"hello-pandas\",\n",
    "    description=\"experiment with KF\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "# You can change the `text` and `emoji_str` parameters here to update the pipeline output\n",
    "def intro_pipeline():\n",
    "    train_eval_df_task = create_pandas_df\n",
    "    header_printer_task = the_head_printer(\n",
    "        test_df = train_eval_df_task.outputs[\"train_set\"],\n",
    "        eval_df = train_eval_df_task.outputs[\"eval_set\"]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200ebfbd-8396-495c-b34e-f0dc1d41a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=intro_pipeline, package_path=\"kf_bq_test.json\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
